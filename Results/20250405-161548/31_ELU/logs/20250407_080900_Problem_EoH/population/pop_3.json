[
    {
        "algorithm": "{Optimize the ELU kernel by using vectorized memory access, loop unrolling, and minimizing redundant calculations while maintaining numerical accuracy.}",
        "function": "#include <torch/extension.h>\n\nconstexpr int VEC_SIZE = 4;\n\n__global__ void elu_kernel(float* input, float* output, int N, float alpha) {\n    int idx = (blockIdx.x * blockDim.x + threadIdx.x) * VEC_SIZE;\n    #pragma unroll\n    for (int i = 0; i < VEC_SIZE; ++i) {\n        if (idx + i < N) {\n            float x = input[idx + i];\n            output[idx + i] = (x >= 0.0f) ? x : alpha * (expf(x) - 1.0f);\n        }\n    }\n}\n\ntorch::Tensor elu_forward(torch::Tensor input, float alpha) {\n    auto output = torch::empty_like(input);\n    int N = input.numel();\n    int threads = 256;  // Reduced for better occupancy with vectorization\n    int blocks = (N + threads * VEC_SIZE - 1) / (threads * VEC_SIZE);\n\n    elu_kernel<<<blocks, threads>>>(input.data_ptr<float>(), output.data_ptr<float>(), N, alpha);\n    return output;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &elu_forward, \"ELU activation forward\");\n}",
        "score": -0.023971199989318848
    },
    {
        "algorithm": "{Optimize the ELU kernel by using vectorized memory accesses, loop unrolling, and minimizing redundant calculations while maintaining numerical accuracy.}",
        "function": "#include <torch/extension.h>\n\n__global__ void elu_kernel(float* input, float* output, int N, float alpha) {\n    const int stride = blockDim.x * gridDim.x;\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    \n    #pragma unroll 4\n    for (; idx < N; idx += stride) {\n        float x = input[idx];\n        output[idx] = (x >= 0) ? x : alpha * (expf(x) - 1);\n    }\n}\n\ntorch::Tensor elu_forward(torch::Tensor input, float alpha) {\n    auto output = torch::empty_like(input);\n    int N = input.numel();\n    int threads = 256;\n    int blocks = min((N + threads - 1) / threads, 1024);\n\n    elu_kernel<<<blocks, threads>>>(input.data_ptr<float>(), output.data_ptr<float>(), N, alpha);\n    return output;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &elu_forward, \"ELU activation forward\");\n}",
        "score": -0.025619200244545937
    },
    {
        "algorithm": "{Optimize the ELU kernel by using vectorized memory accesses, loop unrolling, and minimizing warp divergence while maintaining numerical accuracy.}",
        "function": "#include <torch/extension.h>\n\nconstexpr int VEC_SIZE = 4;\n\n__global__ void elu_kernel(float* input, float* output, int N, float alpha) {\n    int idx = (blockIdx.x * blockDim.x + threadIdx.x) * VEC_SIZE;\n    #pragma unroll\n    for (int i = 0; i < VEC_SIZE; ++i) {\n        if (idx + i < N) {\n            float x = input[idx + i];\n            output[idx + i] = (x >= 0) ? x : alpha * (expf(x) - 1);\n        }\n    }\n}\n\ntorch::Tensor elu_forward(torch::Tensor input, float alpha) {\n    auto output = torch::empty_like(input);\n    int N = input.numel();\n    int threads = 256;\n    int blocks = (N + threads * VEC_SIZE - 1) / (threads * VEC_SIZE);\n\n    elu_kernel<<<blocks, threads>>>(input.data_ptr<float>(), output.data_ptr<float>(), N, alpha);\n    return output;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &elu_forward, \"ELU activation forward\");\n}",
        "score": -0.04129599891602993
    },
    {
        "algorithm": "{Optimize the ELU kernel by processing multiple elements per thread using warp-level primitives and shared memory to reduce global memory accesses while maintaining numerical accuracy.}",
        "function": "#include <torch/extension.h>\n#include <cooperative_groups.h>\n\nconstexpr int VEC_SIZE = 4;\nconstexpr int THREADS_PER_BLOCK = 256;\n\n__global__ void elu_kernel(float* input, float* output, int N, float alpha) {\n    namespace cg = cooperative_groups;\n    cg::thread_block tb = cg::this_thread_block();\n    cg::thread_block_tile<32> tile = cg::tiled_partition<32>(tb);\n\n    int idx = (blockIdx.x * blockDim.x + threadIdx.x) * VEC_SIZE;\n    float4 in_vec;\n    float4 out_vec;\n\n    if (idx + VEC_SIZE - 1 < N) {\n        in_vec = *reinterpret_cast<float4*>(&input[idx]);\n        out_vec.x = (in_vec.x >= 0) ? in_vec.x : alpha * (expf(in_vec.x) - 1);\n        out_vec.y = (in_vec.y >= 0) ? in_vec.y : alpha * (expf(in_vec.y) - 1);\n        out_vec.z = (in_vec.z >= 0) ? in_vec.z : alpha * (expf(in_vec.z) - 1);\n        out_vec.w = (in_vec.w >= 0) ? in_vec.w : alpha * (expf(in_vec.w) - 1);\n        *reinterpret_cast<float4*>(&output[idx]) = out_vec;\n    } else {\n        for (int i = 0; i < VEC_SIZE; ++i) {\n            if (idx + i < N) {\n                float x = input[idx + i];\n                output[idx + i] = (x >= 0) ? x : alpha * (expf(x) - 1);\n            }\n        }\n    }\n}\n\ntorch::Tensor elu_forward(torch::Tensor input, float alpha) {\n    auto output = torch::empty_like(input);\n    int N = input.numel();\n    int blocks = (N + THREADS_PER_BLOCK * VEC_SIZE - 1) / (THREADS_PER_BLOCK * VEC_SIZE);\n\n    elu_kernel<<<blocks, THREADS_PER_BLOCK>>>(input.data_ptr<float>(), output.data_ptr<float>(), N, alpha);\n    return output;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &elu_forward, \"ELU activation forward\");\n}",
        "score": -0.04353599958121777
    },
    {
        "algorithm": "{Optimize the ELU kernel by using vectorized memory access, loop unrolling, and minimizing redundant calculations while maintaining numerical accuracy.}",
        "function": "#include <torch/extension.h>\n\nconstexpr int VEC_SIZE = 4;\n\n__global__ void elu_kernel(float* input, float* output, int N, float alpha) {\n    int idx = (blockIdx.x * blockDim.x + threadIdx.x) * VEC_SIZE;\n    if (idx < N) {\n        float4 in = *reinterpret_cast<float4*>(&input[idx]);\n        float4 out;\n        \n        #pragma unroll\n        for (int i = 0; i < VEC_SIZE; ++i) {\n            float x = ((float*)&in)[i];\n            ((float*)&out)[i] = (x >= 0) ? x : alpha * (expf(x) - 1);\n        }\n        \n        *reinterpret_cast<float4*>(&output[idx]) = out;\n    }\n}\n\ntorch::Tensor elu_forward(torch::Tensor input, float alpha) {\n    auto output = torch::empty_like(input);\n    int N = input.numel();\n    int threads = 256;  // Reduced for better occupancy with vectorized loads\n    int blocks = (N + threads * VEC_SIZE - 1) / (threads * VEC_SIZE);\n\n    elu_kernel<<<blocks, threads>>>(input.data_ptr<float>(), output.data_ptr<float>(), N, alpha);\n    return output;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &elu_forward, \"ELU activation forward\");\n}",
        "score": -0.043785599246621135
    }
]