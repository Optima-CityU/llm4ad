[
    {
        "algorithm": "{Optimize the ELU kernel by using vectorized memory access, loop unrolling, and minimizing redundant calculations while maintaining numerical accuracy.}",
        "function": "#include <torch/extension.h>\n\nconstexpr int VEC_SIZE = 4;\n\n__global__ void elu_kernel(float* input, float* output, int N, float alpha) {\n    int idx = (blockIdx.x * blockDim.x + threadIdx.x) * VEC_SIZE;\n    #pragma unroll\n    for (int i = 0; i < VEC_SIZE; ++i) {\n        if (idx + i < N) {\n            float x = input[idx + i];\n            output[idx + i] = (x >= 0.0f) ? x : alpha * (expf(x) - 1.0f);\n        }\n    }\n}\n\ntorch::Tensor elu_forward(torch::Tensor input, float alpha) {\n    auto output = torch::empty_like(input);\n    int N = input.numel();\n    int threads = 256;  // Reduced for better occupancy with vectorization\n    int blocks = (N + threads * VEC_SIZE - 1) / (threads * VEC_SIZE);\n\n    elu_kernel<<<blocks, threads>>>(input.data_ptr<float>(), output.data_ptr<float>(), N, alpha);\n    return output;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &elu_forward, \"ELU activation forward\");\n}",
        "score": -0.023971199989318848
    },
    {
        "algorithm": "{Optimize the ELU kernel by processing multiple elements per thread using warp-level primitives and shared memory to reduce global memory accesses while maintaining numerical accuracy.}",
        "function": "#include <torch/extension.h>\n#include <cooperative_groups.h>\n\nconstexpr int ELEMENTS_PER_THREAD = 8;\nconstexpr int THREADS_PER_BLOCK = 256;\n\n__global__ void elu_kernel(float* input, float* output, int N, float alpha) {\n    namespace cg = cooperative_groups;\n    cg::thread_block tile = cg::this_thread_block();\n    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    int stride = blockDim.x * gridDim.x * ELEMENTS_PER_THREAD;\n    \n    for (int i = tid * ELEMENTS_PER_THREAD; i < N; i += stride) {\n        #pragma unroll\n        for (int j = 0; j < ELEMENTS_PER_THREAD; ++j) {\n            int idx = i + j;\n            if (idx < N) {\n                float x = input[idx];\n                output[idx] = (x >= 0) ? x : alpha * (expf(x) - 1);\n            }\n        }\n    }\n}\n\ntorch::Tensor elu_forward(torch::Tensor input, float alpha) {\n    auto output = torch::empty_like(input);\n    int N = input.numel();\n    int blocks = (N + THREADS_PER_BLOCK * ELEMENTS_PER_THREAD - 1) / (THREADS_PER_BLOCK * ELEMENTS_PER_THREAD);\n    blocks = min(blocks, 128);\n    \n    elu_kernel<<<blocks, THREADS_PER_BLOCK>>>(input.data_ptr<float>(), output.data_ptr<float>(), N, alpha);\n    return output;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &elu_forward, \"ELU activation forward\");\n}",
        "score": -0.02434880044311285
    },
    {
        "algorithm": "{Optimize the ELU kernel by processing multiple elements per thread using warp-level primitives and shared memory for better memory coalescing and reduced global memory access.}",
        "function": "#include <torch/extension.h>\n\nconstexpr int VEC_SIZE = 4;\nconstexpr int THREADS_PER_BLOCK = 256;\n\n__global__ void elu_kernel(float* input, float* output, int N, float alpha) {\n    __shared__ float smem[THREADS_PER_BLOCK * VEC_SIZE];\n    \n    int tid = threadIdx.x;\n    int idx = (blockIdx.x * THREADS_PER_BLOCK + tid) * VEC_SIZE;\n    \n    if (idx < N) {\n        float4 in = *reinterpret_cast<float4*>(&input[idx]);\n        *reinterpret_cast<float4*>(&smem[tid * VEC_SIZE]) = in;\n    }\n    __syncthreads();\n    \n    #pragma unroll\n    for (int i = 0; i < VEC_SIZE; ++i) {\n        int pos = tid * VEC_SIZE + i;\n        if (idx + i < N) {\n            float x = smem[pos];\n            smem[pos] = (x >= 0) ? x : alpha * (expf(x) - 1);\n        }\n    }\n    __syncthreads();\n    \n    if (idx < N) {\n        float4 out = *reinterpret_cast<float4*>(&smem[tid * VEC_SIZE]);\n        *reinterpret_cast<float4*>(&output[idx]) = out;\n    }\n}\n\ntorch::Tensor elu_forward(torch::Tensor input, float alpha) {\n    auto output = torch::empty_like(input);\n    int N = input.numel();\n    int blocks = (N + THREADS_PER_BLOCK * VEC_SIZE - 1) / (THREADS_PER_BLOCK * VEC_SIZE);\n\n    elu_kernel<<<blocks, THREADS_PER_BLOCK>>>(input.data_ptr<float>(), output.data_ptr<float>(), N, alpha);\n    return output;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &elu_forward, \"ELU activation forward\");\n}",
        "score": -0.02494400031864643
    },
    {
        "algorithm": "{Optimize the ELU kernel by using vectorized memory accesses, loop unrolling, and minimizing redundant calculations while maintaining numerical accuracy.}",
        "function": "#include <torch/extension.h>\n\n__global__ void elu_kernel(float* input, float* output, int N, float alpha) {\n    const int stride = blockDim.x * gridDim.x;\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    \n    #pragma unroll 4\n    for (; idx < N; idx += stride) {\n        float x = input[idx];\n        output[idx] = (x >= 0) ? x : alpha * (expf(x) - 1);\n    }\n}\n\ntorch::Tensor elu_forward(torch::Tensor input, float alpha) {\n    auto output = torch::empty_like(input);\n    int N = input.numel();\n    int threads = 256;\n    int blocks = min((N + threads - 1) / threads, 1024);\n\n    elu_kernel<<<blocks, threads>>>(input.data_ptr<float>(), output.data_ptr<float>(), N, alpha);\n    return output;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &elu_forward, \"ELU activation forward\");\n}",
        "score": -0.025619200244545937
    },
    {
        "algorithm": "{Optimize the ELU kernel by using vectorized memory accesses, loop unrolling, and minimizing warp divergence while maintaining numerical accuracy.}",
        "function": "#include <torch/extension.h>\n\nconstexpr int VEC_SIZE = 4;\n\n__global__ void elu_kernel(float* input, float* output, int N, float alpha) {\n    int idx = (blockIdx.x * blockDim.x + threadIdx.x) * VEC_SIZE;\n    #pragma unroll\n    for (int i = 0; i < VEC_SIZE; ++i) {\n        if (idx + i < N) {\n            float x = input[idx + i];\n            output[idx + i] = (x >= 0) ? x : alpha * (expf(x) - 1);\n        }\n    }\n}\n\ntorch::Tensor elu_forward(torch::Tensor input, float alpha) {\n    auto output = torch::empty_like(input);\n    int N = input.numel();\n    int threads = 256;\n    int blocks = (N + threads * VEC_SIZE - 1) / (threads * VEC_SIZE);\n\n    elu_kernel<<<blocks, threads>>>(input.data_ptr<float>(), output.data_ptr<float>(), N, alpha);\n    return output;\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"forward\", &elu_forward, \"ELU activation forward\");\n}",
        "score": -0.04129599891602993
    }
]